{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "submit = pd.read_csv('../input/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Meaning\n",
    "\n",
    "* Name: 姓名\n",
    "* Age: 年齡\n",
    "* Sex: 性別\n",
    "* Fare: 票價\n",
    "* Ticket_info: 票務資訊\n",
    "* Cabin: 艙號\n",
    "* Parch: 父母/小孩數\n",
    "* SibSp: 兄弟/姊妹/配偶數\n",
    "* Pclass: 乘票等級\n",
    "* Embarked: 港口\n",
    "* PassengerId: 乘客編號\n",
    "* Survived: 是否存活\n",
    "\n",
    "#### 自己加ㄉ\n",
    "* Family_size: 家庭成員數量\n",
    "* IsAlone: 是否單獨一人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_normalization(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb8eab991a264ddbadd1182c67afe2ea5ca14e91"
   },
   "outputs": [],
   "source": [
    "def preprocess(X_data): # train data total 891 entries\n",
    "    # Sex preprocess -> one hot\n",
    "    X_data = pd.concat([pd.get_dummies(X_data['Sex'], prefix = 'sex'), X_data], axis = 1)\n",
    "    X_data.pop('Sex')\n",
    "    # change Name label\n",
    "    X_data['Name'] = X_data['Name'].str.split(', ', expand = True)[1].str.split('.', expand = True)[0]\n",
    "    X_data['Name'] = X_data['Name'].replace(['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    X_data['Name'] = X_data['Name'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "    X_data['Name'] = X_data['Name'].replace('Mme', 'Mrs')\n",
    "    X_data['Name'] = X_data['Name'].astype('category').cat.codes\n",
    "    # modify Ticket_info label\n",
    "    X_data['Ticket_info'] = X_data['Ticket'].apply(lambda x : x.replace('.',\"\").replace('/',\"\").strip().split(' ')[0] if not x.isdigit() else 'X')\n",
    "    X_data['Ticket_info'] = X_data['Ticket_info'].astype('category').cat.codes\n",
    "    X_data.pop('Ticket')\n",
    "    # Cabin only 204\n",
    "    X_data['Cabin'] = X_data['Cabin'].fillna('NoCabin')\n",
    "    X_data['Cabin'] = X_data['Cabin'].apply(lambda x: x.split()[0].strip('1234567890'))\n",
    "    X_data['Cabin'] = X_data['Cabin'].astype('category').cat.codes\n",
    "    # Embarked 港口, only 889\n",
    "    X_data = pd.concat([pd.get_dummies(X_data['Embarked'], prefix = 'embarked'), X_data], axis = 1)\n",
    "    X_data.pop('Embarked')\n",
    "    # age only 714, 依據姓名的稱謂決定年齡\n",
    "    title_age_sum_dict = {}\n",
    "    title_age_counter_dict = {}\n",
    "    title_age_mean_dict = {}\n",
    "    for title in X_data['Name']:\n",
    "        title_age_sum_dict[title] = 0\n",
    "        title_age_counter_dict[title] = 0\n",
    "    for index, data in X_data.iterrows():\n",
    "        if data['Name'] in X_data['Name']:\n",
    "            if not pd.isna(data['Age']):\n",
    "                title_age_sum_dict[data['Name']] += data['Age']\n",
    "                title_age_counter_dict[data['Name']] += 1\n",
    "    print(title_age_sum_dict)\n",
    "    print(title_age_counter_dict)\n",
    "    for title in X_data['Name']:\n",
    "        title_age_mean_dict[title] = title_age_sum_dict[title] / title_age_counter_dict[title]\n",
    "    print(title_age_mean_dict)\n",
    "    mean = X_data['Age'].mean()\n",
    "    for index, data in X_data.iterrows():\n",
    "        if pd.isna(data['Age']):\n",
    "            if pd.isna(title_age_mean_dict[data['Name']]):\n",
    "                X_data.loc[index, 'Age'] = mean\n",
    "            else:\n",
    "                X_data.loc[index, 'Age'] = title_age_mean_dict[data['Name']]\n",
    "    # add label Family_size by Parch and SibSp\n",
    "    X_data['Family_size'] = X_data['Parch'] + X_data['SibSp'] + 1\n",
    "    # add label IsAlone by Family_size\n",
    "    X_data['IsAlone'] = 0\n",
    "    X_data.loc[X_data['Family_size'] == 1, 'IsAlone'] = 1\n",
    "    # pop PassengerId\n",
    "    X_data.pop('PassengerId')\n",
    "    # Name, Age, Fare, Ticket_info, Cabin, Family_size, Parch, SibSp, Pclass -> mean_normalization\n",
    "    X_data['Name'] = mean_normalization(X_data['Name'])\n",
    "    X_data['Fare'] = mean_normalization(X_data['Fare'])\n",
    "    X_data['Age'] = mean_normalization(X_data['Age'])\n",
    "    X_data['Ticket_info'] = mean_normalization(X_data['Ticket_info'])\n",
    "    X_data['Cabin'] = mean_normalization(X_data['Cabin'])\n",
    "    X_data['Family_size'] = mean_normalization(X_data['Family_size'])\n",
    "    X_data['Parch'] = mean_normalization(X_data['Parch'])\n",
    "    X_data['SibSp'] = mean_normalization(X_data['SibSp'])\n",
    "    X_data['Pclass'] = mean_normalization(X_data['Pclass'])\n",
    "    \n",
    "    return X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0897543180f8d84c87f924c833f16f04c012e12f"
   },
   "outputs": [],
   "source": [
    "x_train = preprocess(train)\n",
    "x_test = preprocess(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get y_train, y_test\n",
    "y_train = x_train.pop('Survived')\n",
    "y_test = submit.pop('Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d2ed3fe8a5a93842c4c706f721c7153211f07901"
   },
   "outputs": [],
   "source": [
    "x_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6690da2cc50e2af8ebe2fa7cd9a6d2fc8fad4e2c"
   },
   "outputs": [],
   "source": [
    "x_test.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在這邊寫上你的 Deep Learning Model 吧~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start Code Here\n",
    "\n",
    "### End Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你的 model 沒有使用 validation_split，記得把 `val_acc`、`val_loss` 那兩行**註解**掉。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ccaffea02ae1a3e88a90e9d8abe8956cf338c6a1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 繪製訓練 & 驗證的準確值\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc']) # <= 如果沒有 validation_split 這行記得註解掉\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'lower right')\n",
    "\n",
    "# 繪製訓練 & 驗證的損失值\n",
    "plt.subplot(2,1,2)\n",
    "plt.title('Model loss')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss']) # <= 如果沒有 validation_split 這行記得註解掉\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper right')\n",
    "plt.show()\n",
    "print(\"Loss: {}, Acc: {}\".format(evaluate[0], evaluate[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c9a4ca3715be95872de185e630edae4e843d89c4"
   },
   "outputs": [],
   "source": [
    "predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "655b5e6509b155b5c5117dc7ff5c260bba3546e5"
   },
   "outputs": [],
   "source": [
    "predict = np.where(predict >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "149fcfd43ee61f952f47f618623570a76eb0a470"
   },
   "outputs": [],
   "source": [
    "predict_train = model.predict(x_train)\n",
    "predict_train = np.where(predict_train >= 0.5, 1, 0)\n",
    "counter = 0\n",
    "for i in range(len(predict_train)):\n",
    "    if predict_train[i][0] == y_train[i]:\n",
    "        counter += 1\n",
    "print(counter)\n",
    "print(counter / len(predict_train))\n",
    "\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2a3b615061726248c910ecbb90d3e717ede665b2"
   },
   "outputs": [],
   "source": [
    "submit['Survived'] = predict\n",
    "submit.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "defd02419bcc1b209bc8e10ce114621b219e869c"
   },
   "outputs": [],
   "source": [
    "# import the modules we'll need\n",
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "\n",
    "# function that takes in a dataframe and creates a text link to  \n",
    "# download it (will only work for files < 2MB or so)\n",
    "def create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n",
    "    csv = df.to_csv(index = False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload = payload, title = title, filename = filename)\n",
    "    return HTML(html)\n",
    "\n",
    "# create a random sample dataframe\n",
    "df = pd.DataFrame(np.random.randn(50, 4), columns = list('ABCD'))\n",
    "\n",
    "# create a link to download the dataframe\n",
    "create_download_link(submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "14334753582617a8181c9b8e72bd82c0ac25b2a6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
