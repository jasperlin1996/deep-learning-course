{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "submit = pd.read_csv('../input/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "304cd0bd71a8af6106dee6b5153e63580a14a88e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb8eab991a264ddbadd1182c67afe2ea5ca14e91"
   },
   "outputs": [],
   "source": [
    "def mean_normalization(data):\n",
    "    return (data - np.min(data))/(np.max(data)-np.min(data))\n",
    "\n",
    "def preprocess(train): # 偷偷借用 train 來當變數\n",
    "    # total 891 entries\n",
    "    # Embarked only 889\n",
    "    #train.head(5)\n",
    "    # Sex preprocess -> one hot\n",
    "    train = pd.concat([pd.get_dummies(train['Sex'], prefix='sex'), train], axis = 1)\n",
    "    train.pop('Sex')\n",
    "    # Name ? (先丟掉)\n",
    "    # train.pop('Name')\n",
    "    train['Name'] = train['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "    train['Name'] = train['Name'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    train['Name'] = train['Name'].replace('Mlle', 'Miss')\n",
    "    train['Name'] = train['Name'].replace('Ms', 'Miss')\n",
    "    train['Name'] = train['Name'].replace('Mme', 'Mrs')\n",
    "    train['Name'] = train['Name'].astype('category').cat.codes\n",
    "    # Ticket ?\n",
    "    train['Ticket_info'] = train['Ticket'].apply(lambda x : x.replace('.',\"\").replace('/',\"\").strip().split(' ')[0] if not x.isdigit() else 'X')\n",
    "    train['Ticket_info'] = train['Ticket_info'].astype('category').cat.codes\n",
    "    train.pop('Ticket')\n",
    "    # Cabin only 204\n",
    "    train['Cabin'] = train['Cabin'].fillna('NoCabin')\n",
    "    train['Cabin'] = train['Cabin'].apply(lambda x: x.split()[0].strip('1234567890'))\n",
    "    train['Cabin'] = train['Cabin'].astype('category').cat.codes\n",
    "    #train = pd.concat([pd.get_dummies(train['Cabin']), train], axis = 1)\n",
    "    #train.pop('Cabin')\n",
    "    # Embarked 港口\n",
    "    # train['Embarked'] = train['Embarked'].astype('category').cat.codes\n",
    "    train = pd.concat([pd.get_dummies(train['Embarked'], prefix='embarked'), train], axis = 1)\n",
    "    train.pop('Embarked')\n",
    "    # age only 714\n",
    "    # train['Age'] = train['Age'].fillna(train['Age'].mean())\n",
    "    title_age_sum_dict = {}\n",
    "    title_age_counter_dict = {}\n",
    "    title_age_mean_dict = {}\n",
    "    for title in train['Name']:\n",
    "        title_age_sum_dict[title] = 0\n",
    "        title_age_counter_dict[title] = 0\n",
    "    for index, data in train.iterrows():\n",
    "        if data['Name'] in train['Name']:\n",
    "            if not pd.isna(data['Age']):\n",
    "                title_age_sum_dict[data['Name']] += data['Age']\n",
    "                title_age_counter_dict[data['Name']] += 1\n",
    "    print(title_age_sum_dict)\n",
    "    print(title_age_counter_dict)\n",
    "    for title in train['Name']:\n",
    "        title_age_mean_dict[title] = title_age_sum_dict[title]/title_age_counter_dict[title]\n",
    "    print(title_age_mean_dict)\n",
    "    mean = train['Age'].mean()\n",
    "    for index, data in train.iterrows():\n",
    "        if pd.isna(data['Age']):\n",
    "            if pd.isna(title_age_mean_dict[data['Name']]):\n",
    "                train.loc[index, 'Age'] = mean\n",
    "            else:\n",
    "                train.loc[index, 'Age'] = title_age_mean_dict[data['Name']]\n",
    "    train['Family_size'] = train['Parch'] + train['SibSp'] + 1\n",
    "    \n",
    "    train['IsAlone'] = 0\n",
    "    train.loc[train['Family_size'] == 1, 'IsAlone'] = 1\n",
    "    # PassengerId\n",
    "    train.pop('PassengerId')\n",
    "    ### NAME AGE FARE TICKET_INFO -> mean_normalization\n",
    "    train['Name'] = mean_normalization(train['Name'])\n",
    "    train['Fare'] = mean_normalization(train['Fare'])\n",
    "    train['Age'] = mean_normalization(train['Age'])\n",
    "    train['Ticket_info'] = mean_normalization(train['Ticket_info'])\n",
    "    train['Cabin'] = mean_normalization(train['Cabin'])\n",
    "    train['Family_size'] = mean_normalization(train['Family_size'])\n",
    "    train['Parch'] = mean_normalization(train['Parch'])\n",
    "    train['SibSp'] = mean_normalization(train['SibSp'])\n",
    "    train['Pclass'] = mean_normalization(train['Pclass'])\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0897543180f8d84c87f924c833f16f04c012e12f"
   },
   "outputs": [],
   "source": [
    "x_train = preprocess(train)\n",
    "x_test = preprocess(test)\n",
    "#fill = np.zeros(len(x_test))\n",
    "#x_test['T'] = pd.Series(fill)\n",
    "y_train = x_train.pop('Survived')\n",
    "y_test = submit.pop('Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ffb575aec12c43c3c7171081809074806a10cdf9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d2ed3fe8a5a93842c4c706f721c7153211f07901"
   },
   "outputs": [],
   "source": [
    "x_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6690da2cc50e2af8ebe2fa7cd9a6d2fc8fad4e2c"
   },
   "outputs": [],
   "source": [
    "x_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "080adb51e0203f2e979a9adba0abd66504bf1508"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras import regularizers\n",
    "#\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "layer_1 = Dense(5012, activation='relu',input_dim = 15, kernel_initializer='random_uniform',bias_initializer='zeros',\n",
    "               kernel_regularizer=regularizers.l2(0.0004))\n",
    "dp_1 = Dropout(0.3)\n",
    "layer_2 = Dense(2048, activation='relu', kernel_initializer='random_uniform',bias_initializer='zeros',\n",
    "               kernel_regularizer=regularizers.l2(0.0004))\n",
    "dp_2 = Dropout(0.3)\n",
    "layer_3 = Dense(1024, activation='relu', kernel_initializer='random_uniform',bias_initializer='zeros',\n",
    "               kernel_regularizer=regularizers.l2(0.0004))\n",
    "dp_3 = Dropout(0.3)\n",
    "layer_4 = Dense(500, activation='relu', kernel_initializer='random_uniform',bias_initializer='zeros',\n",
    "               kernel_regularizer=regularizers.l2(0.0004))\n",
    "dp_4 = Dropout(0.2)\n",
    "layer_5 = Dense(500, activation='relu', kernel_initializer='random_uniform',bias_initializer='zeros',\n",
    "               kernel_regularizer=regularizers.l2(0.0004))\n",
    "dp_5 = Dropout(0.1)\n",
    "layer_6 = Dense(100, activation='relu', kernel_initializer='random_uniform',bias_initializer='zeros',\n",
    "               kernel_regularizer=regularizers.l2(0.0004))\n",
    "layer_7 = Dense(1, activation='relu', kernel_initializer='random_uniform',bias_initializer='zeros',\n",
    "               kernel_regularizer=regularizers.l2(0.0004))\n",
    "output_layer = Dense(1, activation='sigmoid',\n",
    "                    activity_regularizer=regularizers.l1(0.0004))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1ba29db17133ee63e7ff53f1cb8debc820b8b242"
   },
   "outputs": [],
   "source": [
    "model.add(layer_1)\n",
    "model.add(dp_1)\n",
    "model.add(layer_2)\n",
    "model.add(dp_2)\n",
    "model.add(layer_3)\n",
    "model.add(dp_3)\n",
    "model.add(layer_4)\n",
    "model.add(dp_4)\n",
    "model.add(layer_5)\n",
    "model.add(dp_5)\n",
    "model.add(layer_6)\n",
    "model.add(layer_7)\n",
    "\n",
    "model.add(output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "66e9fa23ea16eaa52134b66657ce7eb0c0df87de",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nadam = keras.optimizers.Nadam(lr=0.0007, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "adam = keras.optimizers.Adam(lr=0.0004, beta_1=0.9, beta_2=0.999, decay = 0.002)\n",
    "model.compile(optimizer = adam, loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3d0a31c0256ca3d702916ad8a215defe164c6a46"
   },
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.02, patience=20, verbose=1, mode='auto', baseline=None, restore_best_weights=False)\n",
    "history = model.fit(x_train, y_train, batch_size = 104, epochs = 500, validation_split=0.112, verbose = 1, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "67970824a48bdbe8437911f1975703915cd8c5d8"
   },
   "outputs": [],
   "source": [
    "x_test.head(3)\n",
    "evaluate = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ccaffea02ae1a3e88a90e9d8abe8956cf338c6a1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#print(history.history)\n",
    "#print(dir(history.history.keys))\n",
    "\n",
    "# 繪製訓練 & 驗證的準確值\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower right')\n",
    "\n",
    "# 繪製訓練 & 驗證的損失值\n",
    "plt.subplot(2,1,2)\n",
    "plt.title('Model loss')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()\n",
    "print(\"Loss: {}, Acc: {}\".format(evaluate[0], evaluate[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c9a4ca3715be95872de185e630edae4e843d89c4"
   },
   "outputs": [],
   "source": [
    "predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "655b5e6509b155b5c5117dc7ff5c260bba3546e5"
   },
   "outputs": [],
   "source": [
    "predict = np.where(predict >= 0.5, 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "149fcfd43ee61f952f47f618623570a76eb0a470"
   },
   "outputs": [],
   "source": [
    "predict_train = model.predict(x_train)\n",
    "predict_train = np.where(predict_train >= 0.5, 1, 0)\n",
    "counter = 0\n",
    "for i in range(len(predict_train)):\n",
    "    if predict_train[i][0] == y_train[i]:\n",
    "        counter += 1\n",
    "print(counter)\n",
    "print(counter/len(predict_train))\n",
    "\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2a3b615061726248c910ecbb90d3e717ede665b2"
   },
   "outputs": [],
   "source": [
    "submit['Survived'] = predict\n",
    "submit.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "defd02419bcc1b209bc8e10ce114621b219e869c"
   },
   "outputs": [],
   "source": [
    "# import the modules we'll need\n",
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "\n",
    "# function that takes in a dataframe and creates a text link to  \n",
    "# download it (will only work for files < 2MB or so)\n",
    "def create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "# create a random sample dataframe\n",
    "df = pd.DataFrame(np.random.randn(50, 4), columns=list('ABCD'))\n",
    "\n",
    "# create a link to download the dataframe\n",
    "create_download_link(submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "14334753582617a8181c9b8e72bd82c0ac25b2a6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
