{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nsubmit = pd.read_csv('../input/gender_submission.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "304cd0bd71a8af6106dee6b5153e63580a14a88e"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fb8eab991a264ddbadd1182c67afe2ea5ca14e91"
      },
      "cell_type": "code",
      "source": "def mean_normalization(data):\n    return (data - np.min(data))/(np.max(data)-np.min(data))\n\ndef preprocess(train): # 偷偷借用 train 來當變數\n    # total 891 entries\n    # Embarked only 889\n    #train.head(5)\n    # Sex preprocess -> one hot\n    train = pd.concat([pd.get_dummies(train['Sex'], prefix='sex'), train], axis = 1)\n    train.pop('Sex')\n    # Name ? (先丟掉)\n    # train.pop('Name')\n    train['Name'] = train['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n    train['Name'] = train['Name'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    train['Name'] = train['Name'].replace('Mlle', 'Miss')\n    train['Name'] = train['Name'].replace('Ms', 'Miss')\n    train['Name'] = train['Name'].replace('Mme', 'Mrs')\n    train['Name'] = train['Name'].astype('category').cat.codes\n    # Ticket ?\n    train['Ticket_info'] = train['Ticket'].apply(lambda x : x.replace('.',\"\").replace('/',\"\").strip().split(' ')[0] if not x.isdigit() else 'X')\n    train['Ticket_info'] = train['Ticket_info'].astype('category').cat.codes\n    train.pop('Ticket')\n    # Cabin only 204\n    train['Cabin'] = train['Cabin'].fillna('NoCabin')\n    train['Cabin'] = train['Cabin'].apply(lambda x: x.split()[0].strip('1234567890'))\n    train['Cabin'] = train['Cabin'].astype('category').cat.codes\n    #train = pd.concat([pd.get_dummies(train['Cabin']), train], axis = 1)\n    #train.pop('Cabin')\n    # Embarked 港口\n    # train['Embarked'] = train['Embarked'].astype('category').cat.codes\n    train = pd.concat([pd.get_dummies(train['Embarked'], prefix='embarked'), train], axis = 1)\n    train.pop('Embarked')\n    # age only 714\n    # train['Age'] = train['Age'].fillna(train['Age'].mean())\n    title_age_sum_dict = {}\n    title_age_counter_dict = {}\n    title_age_mean_dict = {}\n    for title in train['Name']:\n        title_age_sum_dict[title] = 0\n        title_age_counter_dict[title] = 0\n    for index, data in train.iterrows():\n        if data['Name'] in train['Name']:\n            if not pd.isna(data['Age']):\n                title_age_sum_dict[data['Name']] += data['Age']\n                title_age_counter_dict[data['Name']] += 1\n    print(title_age_sum_dict)\n    print(title_age_counter_dict)\n    for title in train['Name']:\n        title_age_mean_dict[title] = title_age_sum_dict[title]/title_age_counter_dict[title]\n    print(title_age_mean_dict)\n    mean = train['Age'].mean()\n    for index, data in train.iterrows():\n        if pd.isna(data['Age']):\n            if pd.isna(title_age_mean_dict[data['Name']]):\n                train.loc[index, 'Age'] = mean\n            else:\n                train.loc[index, 'Age'] = title_age_mean_dict[data['Name']]\n    train['Family_size'] = train['Parch'] + train['SibSp'] + 1\n    \n    train['IsAlone'] = 0\n    train.loc[train['Family_size'] == 1, 'IsAlone'] = 1\n    # PassengerId\n    train.pop('PassengerId')\n    ### NAME AGE FARE TICKET_INFO -> mean_normalization\n    train['Name'] = mean_normalization(train['Name'])\n    train['Fare'] = mean_normalization(train['Fare'])\n    train['Age'] = mean_normalization(train['Age'])\n    train['Ticket_info'] = mean_normalization(train['Ticket_info'])\n    train['Cabin'] = mean_normalization(train['Cabin'])\n    train['Family_size'] = mean_normalization(train['Family_size'])\n    train['Parch'] = mean_normalization(train['Parch'])\n    train['SibSp'] = mean_normalization(train['SibSp'])\n    train['Pclass'] = mean_normalization(train['Pclass'])\n    \n    return train",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0897543180f8d84c87f924c833f16f04c012e12f"
      },
      "cell_type": "code",
      "source": "x_train = preprocess(train)\nx_test = preprocess(test)\n#fill = np.zeros(len(x_test))\n#x_test['T'] = pd.Series(fill)\ny_train = x_train.pop('Survived')\ny_test = submit.pop('Survived')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ffb575aec12c43c3c7171081809074806a10cdf9"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d2ed3fe8a5a93842c4c706f721c7153211f07901"
      },
      "cell_type": "code",
      "source": "x_train.head(20)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6690da2cc50e2af8ebe2fa7cd9a6d2fc8fad4e2c"
      },
      "cell_type": "code",
      "source": "x_test.head(1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "080adb51e0203f2e979a9adba0abd66504bf1508"
      },
      "cell_type": "code",
      "source": "import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nfrom keras import regularizers\n#\n\nmodel = Sequential()\n\nlayer_1 = Dense(5012, activation='relu',input_dim = 15, kernel_initializer='random_uniform',bias_initializer='zeros',\n               kernel_regularizer=regularizers.l2(0.0004))\ndp_1 = Dropout(0.3)\nlayer_2 = Dense(2048, activation='relu', kernel_initializer='random_uniform',bias_initializer='zeros',\n               kernel_regularizer=regularizers.l2(0.0004))\ndp_2 = Dropout(0.3)\nlayer_3 = Dense(1024, activation='relu', kernel_initializer='random_uniform',bias_initializer='zeros',\n               kernel_regularizer=regularizers.l2(0.0004))\ndp_3 = Dropout(0.3)\nlayer_4 = Dense(500, activation='relu', kernel_initializer='random_uniform',bias_initializer='zeros',\n               kernel_regularizer=regularizers.l2(0.0004))\ndp_4 = Dropout(0.2)\nlayer_5 = Dense(500, activation='relu', kernel_initializer='random_uniform',bias_initializer='zeros',\n               kernel_regularizer=regularizers.l2(0.0004))\ndp_5 = Dropout(0.1)\nlayer_6 = Dense(100, activation='relu', kernel_initializer='random_uniform',bias_initializer='zeros',\n               kernel_regularizer=regularizers.l2(0.0004))\nlayer_7 = Dense(1, activation='relu', kernel_initializer='random_uniform',bias_initializer='zeros',\n               kernel_regularizer=regularizers.l2(0.0004))\noutput_layer = Dense(1, activation='sigmoid',\n                    activity_regularizer=regularizers.l1(0.0004))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1ba29db17133ee63e7ff53f1cb8debc820b8b242"
      },
      "cell_type": "code",
      "source": "model.add(layer_1)\nmodel.add(dp_1)\nmodel.add(layer_2)\nmodel.add(dp_2)\nmodel.add(layer_3)\nmodel.add(dp_3)\nmodel.add(layer_4)\nmodel.add(dp_4)\nmodel.add(layer_5)\nmodel.add(dp_5)\nmodel.add(layer_6)\nmodel.add(layer_7)\n\nmodel.add(output_layer)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "66e9fa23ea16eaa52134b66657ce7eb0c0df87de",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "nadam = keras.optimizers.Nadam(lr=0.0007, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\nadam = keras.optimizers.Adam(lr=0.0004, beta_1=0.9, beta_2=0.999, decay = 0.002)\nmodel.compile(optimizer = adam, loss = 'binary_crossentropy', metrics=['accuracy'])\nmodel.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3d0a31c0256ca3d702916ad8a215defe164c6a46"
      },
      "cell_type": "code",
      "source": "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.02, patience=20, verbose=1, mode='auto', baseline=None, restore_best_weights=False)\nhistory = model.fit(x_train, y_train, batch_size = 104, epochs = 500, validation_split=0.112, verbose = 1, callbacks=[early_stop])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "67970824a48bdbe8437911f1975703915cd8c5d8"
      },
      "cell_type": "code",
      "source": "x_test.head(3)\nevaluate = model.evaluate(x_test, y_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ccaffea02ae1a3e88a90e9d8abe8956cf338c6a1",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\n\n#print(history.history)\n#print(dir(history.history.keys))\n\n# 繪製訓練 & 驗證的準確值\nplt.subplot(2,1,1)\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\n\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='lower right')\n\n# 繪製訓練 & 驗證的損失值\nplt.subplot(2,1,2)\nplt.title('Model loss')\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\n\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper right')\nplt.show()\nprint(\"Loss: {}, Acc: {}\".format(evaluate[0], evaluate[1]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c9a4ca3715be95872de185e630edae4e843d89c4"
      },
      "cell_type": "code",
      "source": "predict = model.predict(x_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "655b5e6509b155b5c5117dc7ff5c260bba3546e5"
      },
      "cell_type": "code",
      "source": "predict = np.where(predict >= 0.5, 1,0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "149fcfd43ee61f952f47f618623570a76eb0a470"
      },
      "cell_type": "code",
      "source": "predict_train = model.predict(x_train)\npredict_train = np.where(predict_train >= 0.5, 1, 0)\ncounter = 0\nfor i in range(len(predict_train)):\n    if predict_train[i][0] == y_train[i]:\n        counter += 1\nprint(counter)\nprint(counter/len(predict_train))\n\nprint(predict)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2a3b615061726248c910ecbb90d3e717ede665b2"
      },
      "cell_type": "code",
      "source": "submit['Survived'] = predict\nsubmit.to_csv('submission.csv', index=False)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "defd02419bcc1b209bc8e10ce114621b219e869c"
      },
      "cell_type": "code",
      "source": "# import the modules we'll need\nfrom IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n# create a random sample dataframe\ndf = pd.DataFrame(np.random.randn(50, 4), columns=list('ABCD'))\n\n# create a link to download the dataframe\ncreate_download_link(submit)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "14334753582617a8181c9b8e72bd82c0ac25b2a6"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}